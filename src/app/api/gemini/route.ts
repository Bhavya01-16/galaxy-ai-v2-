import { NextRequest, NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { z } from "zod";

// ============================================================================
// ZOD VALIDATION SCHEMA
// ============================================================================

const GeminiRequestSchema = z.object({
  prompt: z.string().min(1, "Prompt is required"),
  systemPrompt: z.string().optional(),
  model: z.enum(["gemini-2.0-flash", "gemini-1.5-flash-8b", "gemini-2.0-flash-lite"]).default("gemini-2.0-flash"),
  temperature: z.number().min(0).max(2).default(0.7),
  maxTokens: z.number().min(1).max(8192).default(2048),
  imageData: z.string().optional(),
});

// ============================================================================
// GEMINI API ROUTE - Server-side execution
// ============================================================================

// Enable simulation mode (bypasses API, returns realistic responses)
const SIMULATION_MODE = process.env.GEMINI_SIMULATION_MODE === "true" || process.env.GEMINI_SIMULATION_MODE === "1";

// Support multiple API keys for rotation (comma-separated in .env)
const getAllApiKeys = (): string[] => {
  return process.env.GOOGLE_AI_API_KEY?.split(",").map(k => k.trim()).filter(Boolean) || [];
};

// Generate realistic simulated response
const generateSimulatedResponse = (prompt: string, systemPrompt?: string, imageData?: string): string => {
  const hasImage = !!imageData;
  const promptLower = prompt.toLowerCase();
  
  // Smart simulation based on prompt content
  if (promptLower.includes("summarize") || promptLower.includes("summary")) {
    return `[Simulated Response]\n\nSummary:\n${prompt.substring(0, 200)}...\n\nThis is a simulated summary response. The actual content would be generated by Gemini AI when API keys are available.`;
  }
  
  if (promptLower.includes("translate") || promptLower.includes("translation")) {
    return `[Simulated Response]\n\nTranslation:\n"${prompt.substring(0, 100)}..." â†’ [Translated text would appear here]\n\nThis is a simulated translation. Enable real API keys for actual translations.`;
  }
  
  if (promptLower.includes("code") || promptLower.includes("programming") || promptLower.includes("function")) {
    return `[Simulated Response]\n\nHere's a code example:\n\n\`\`\`javascript\nfunction example() {\n  // ${prompt.substring(0, 50)}...\n  return "result";\n}\n\`\`\`\n\nThis is a simulated code response. Real API keys will generate actual code.`;
  }
  
  if (hasImage) {
    return `[Simulated Response - Image Analysis]\n\nI can see an image in your request. In simulation mode, I would analyze:\n- Image content and objects\n- Text in the image\n- Colors and composition\n\nEnable real API keys for actual image analysis using Gemini Vision.`;
  }
  
  // Default intelligent response
  return `[Simulated Response]\n\nBased on your prompt: "${prompt.substring(0, 150)}..."\n\nThis is a simulated AI response. Your workflow will continue normally, but to get real Gemini AI responses:\n\n1. Add valid API keys to .env.local\n2. Set GEMINI_SIMULATION_MODE=false\n3. Restart server\n\nFor now, this response allows you to test your workflow structure without API limits.`;
};

// Track exhausted keys (reset after 1 hour)
const exhaustedKeys = new Map<string, number>();
const EXHAUSTED_RESET_TIME = 60 * 60 * 1000; // 1 hour

const getAvailableKeys = (): string[] => {
  const allKeys = getAllApiKeys();
  const now = Date.now();
  
  // Filter out exhausted keys (unless reset time passed)
  return allKeys.filter(key => {
    const exhaustedAt = exhaustedKeys.get(key);
    if (!exhaustedAt) return true;
    if (now - exhaustedAt > EXHAUSTED_RESET_TIME) {
      exhaustedKeys.delete(key);
      return true;
    }
    return false;
  });
};

const markKeyExhausted = (key: string) => {
  exhaustedKeys.set(key, Date.now());
  console.log(`[Gemini API] Marked key as exhausted: ${key.substring(0, 20)}...`);
};

// Clear all exhausted keys (useful for debugging)
export function clearExhaustedKeys() {
  exhaustedKeys.clear();
  console.log(`[Gemini API] Cleared all exhausted keys`);
}

// GET endpoint for debugging API key status
export async function GET() {
  const allKeys = getAllApiKeys();
  const availableKeys = getAvailableKeys();
  const exhausted = Array.from(exhaustedKeys.entries()).map(([key, timestamp]) => ({
    key: key.substring(0, 20) + "...",
    exhaustedAt: new Date(timestamp).toISOString(),
    resetIn: Math.max(0, Math.ceil((EXHAUSTED_RESET_TIME - (Date.now() - timestamp)) / 1000 / 60)),
  }));

  return NextResponse.json({
    totalKeys: allKeys.length,
    availableKeys: availableKeys.length,
    exhaustedKeys: exhaustedKeys.size,
    keys: {
      all: allKeys.map(k => k.substring(0, 20) + "..."),
      available: availableKeys.map(k => k.substring(0, 20) + "..."),
      exhausted,
    },
    cacheSize: responseCache.size,
  });
}

// Simple in-memory cache (in production, use Redis)
const responseCache = new Map<string, { text: string; timestamp: number }>();
const CACHE_TTL = 5 * 60 * 1000; // 5 minutes

const getCacheKey = (prompt: string, model: string, systemPrompt?: string): string => {
  return `${model}:${systemPrompt || ""}:${prompt.substring(0, 100)}`;
};

const getCachedResponse = (key: string): string | null => {
  const cached = responseCache.get(key);
  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    return cached.text;
  }
  responseCache.delete(key);
  return null;
};

const setCachedResponse = (key: string, text: string) => {
  responseCache.set(key, { text, timestamp: Date.now() });
  
  // Clean old cache entries (keep last 100)
  if (responseCache.size > 100) {
    const entries = Array.from(responseCache.entries());
    entries.sort((a, b) => b[1].timestamp - a[1].timestamp);
    responseCache.clear();
    entries.slice(0, 100).forEach(([k, v]) => responseCache.set(k, v));
  }
};

export async function POST(request: NextRequest) {
  let body: unknown = null;
  
  try {
    // SIMULATION MODE: Return simulated response immediately
    if (SIMULATION_MODE) {
      try {
        body = await request.json();
      } catch {
        body = { prompt: "Test prompt" };
      }
      
      const validationResult = GeminiRequestSchema.safeParse(body);
      if (validationResult.success) {
        const { prompt, systemPrompt, imageData } = validationResult.data;
        const simulatedText = generateSimulatedResponse(prompt, systemPrompt, imageData);
        
        return NextResponse.json({
          success: true,
          text: simulatedText,
          model: "simulated",
          simulationMode: true,
        });
      }
    }
    
    // Validate at least one API key exists (only if not in simulation mode)
    const allKeys = getAllApiKeys();
    if (allKeys.length === 0) {
      // If no keys, automatically use simulation mode
      try {
        body = await request.json();
      } catch {
        body = { prompt: "Test prompt" };
      }
      
      const validationResult = GeminiRequestSchema.safeParse(body);
      if (validationResult.success) {
        const { prompt, systemPrompt, imageData } = validationResult.data;
        const simulatedText = generateSimulatedResponse(prompt, systemPrompt, imageData);
        
        return NextResponse.json({
          success: true,
          text: simulatedText,
          model: "simulated",
          simulationMode: true,
          note: "No API keys configured - using simulation mode",
        });
      }
      
      return NextResponse.json(
        { 
          success: false, 
          error: "GOOGLE_AI_API_KEY not configured. Add it to .env.local (comma-separated for multiple keys) OR set GEMINI_SIMULATION_MODE=true" 
        },
        { status: 500 }
      );
    }

    // Parse and validate request body with Zod
    try {
      body = await request.json();
    } catch {
      return NextResponse.json(
        { 
          success: false, 
          error: "Invalid JSON in request body",
        },
        { status: 400 }
      );
    }
    
    const validationResult = GeminiRequestSchema.safeParse(body);
    
    if (!validationResult.success) {
      return NextResponse.json(
        { 
          success: false, 
          error: "Validation failed",
          details: validationResult.error.flatten().fieldErrors,
        },
        { status: 400 }
      );
    }

    const { prompt, systemPrompt, model, temperature, maxTokens, imageData } = validationResult.data;

    // Check cache first (only for text-only, no image)
    if (!imageData) {
      const cacheKey = getCacheKey(prompt, model, systemPrompt);
      const cached = getCachedResponse(cacheKey);
      if (cached) {
        return NextResponse.json({
          success: true,
          text: cached,
          model: model,
          cached: true,
        });
      }
    }

    // Get available API keys (reuse allKeys from earlier declaration)
    const availableKeys = getAvailableKeys();
    
    // Debug logging
    console.log(`[Gemini API] Total keys: ${allKeys.length}, Available: ${availableKeys.length}, Exhausted: ${exhaustedKeys.size}`);
    
    if (availableKeys.length === 0) {
      // Clear exhausted keys if all are exhausted (might be stale state)
      if (exhaustedKeys.size > 0 && allKeys.length > 0) {
        console.log(`[Gemini API] Clearing exhausted keys cache - trying fresh...`);
        exhaustedKeys.clear();
        const freshKeys = getAvailableKeys();
        if (freshKeys.length > 0) {
          // Retry with fresh keys
          // Continue to try keys below
        } else {
          return NextResponse.json({
            success: true,
            text: `[All API Keys Exhausted - Simulated Response]\n\nTotal keys configured: ${allKeys.length}\nAll keys have reached their rate limit.\n\nIMPORTANT: Make sure:\n1. Keys are from DIFFERENT projects (not same project!)\n2. Server was restarted after adding keys\n3. Keys are comma-separated in .env.local\n\nYour prompt was: "${promptText}..."`,
            model: "simulated",
            rateLimited: true,
            debug: {
              totalKeys: allKeys.length,
              exhaustedCount: exhaustedKeys.size,
            },
          });
        }
      } else {
        const promptText = prompt.substring(0, 100);
        return NextResponse.json({
          success: true,
          text: `[No API Keys Available - Simulated Response]\n\nNo API keys are available. Check your .env.local file.\n\nYour prompt was: "${promptText}..."`,
          model: "simulated",
          rateLimited: true,
        });
      }
    }
    
    // Use fresh keys if we cleared the cache
    const keysToTry = availableKeys.length > 0 ? availableKeys : getAvailableKeys();

    // Throttle requests - small delay to avoid rate limits
    await new Promise(resolve => setTimeout(resolve, 500));

    // Try each available key until one works
    for (const currentKey of keysToTry) {
      console.log(`[Gemini API] Trying key: ${currentKey.substring(0, 20)}...`);
      try {
        // Initialize Gemini with current API key
        const genAI = new GoogleGenerativeAI(currentKey);
        
        // Get model with configuration
        const geminiModel = genAI.getGenerativeModel({
          model: model,
          generationConfig: {
            temperature: temperature,
            maxOutputTokens: maxTokens,
          },
          ...(systemPrompt && {
            systemInstruction: systemPrompt,
          }),
        });

        let result;

        // Check if image is provided (multimodal)
        if (imageData && typeof imageData === "string") {
          // Extract base64 data from data URL if needed
          let mimeType = "image/jpeg";
          let base64Data = imageData;

          if (imageData.startsWith("data:")) {
            const matches = imageData.match(/^data:(.+);base64,(.+)$/);
            if (matches) {
              mimeType = matches[1];
              base64Data = matches[2];
            }
          }

          // Multimodal generation (text + image)
          result = await geminiModel.generateContent([
            prompt,
            {
              inlineData: {
                mimeType,
                data: base64Data,
              },
            },
          ]);
        } else {
          // Text-only generation
          result = await geminiModel.generateContent(prompt);
        }

        const response = await result.response;
        const text = response.text();

        // Cache the response (only for text-only, no image)
        if (!imageData && text) {
          const cacheKey = getCacheKey(prompt, model, systemPrompt);
          setCachedResponse(cacheKey, text);
        }

        return NextResponse.json({
          success: true,
          text: text || "No response generated",
          model: model,
          usage: {
            promptTokens: response.usageMetadata?.promptTokenCount,
            completionTokens: response.usageMetadata?.candidatesTokenCount,
            totalTokens: response.usageMetadata?.totalTokenCount,
          },
        });

      } catch (keyError) {
        const errorMsg = keyError instanceof Error ? keyError.message : "Unknown error";
        
        // Check if this key is rate limited
        if (errorMsg.includes("429") || errorMsg.includes("quota") || errorMsg.includes("Too Many Requests") || errorMsg.includes("rate limit") || errorMsg.includes("exceeded")) {
          console.log(`[Gemini API] Key rate limited, marking exhausted and trying next...`);
          markKeyExhausted(currentKey);
          
          // If this is the last key, don't continue
          if (keysToTry.indexOf(currentKey) === keysToTry.length - 1) {
            // Last key exhausted - will return simulated response below
            break;
          }
          continue; // Try next key
        }
        
        // For other errors, throw immediately
        throw keyError;
      }
    }

    // All keys exhausted - return simulated response
    const simulatedText = generateSimulatedResponse(prompt, systemPrompt, imageData);
    return NextResponse.json({
      success: true,
      text: simulatedText,
      model: "simulated",
      rateLimited: true,
      note: "All API keys exhausted - using simulation mode. Set GEMINI_SIMULATION_MODE=true to always use simulation.",
    });

  } catch (error) {
    console.error("Gemini API Error:", error);
    
    const errorMessage = error instanceof Error ? error.message : "Unknown error";
    
    // Safely extract prompt from body
    let promptText = "N/A";
    let systemPromptText: string | undefined;
    let imageDataText: string | undefined;
    
    if (body && typeof body === "object" && "prompt" in body && typeof body.prompt === "string") {
      promptText = body.prompt;
      systemPromptText = "systemPrompt" in body && typeof body.systemPrompt === "string" ? body.systemPrompt : undefined;
      imageDataText = "imageData" in body && typeof body.imageData === "string" ? body.imageData : undefined;
    }
    
    // For any error, return simulated response so workflow continues
    const simulatedText = generateSimulatedResponse(promptText, systemPromptText, imageDataText);
    return NextResponse.json({
      success: true,
      text: simulatedText,
      model: "simulated",
      error: errorMessage,
      note: "API error occurred - using simulation mode. Set GEMINI_SIMULATION_MODE=true to always use simulation.",
    });
  }
}
